{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import itertools\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, PowerTransformer\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv('wine-quality.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change spaces in column names to underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features: list[str] = list(df.select_dtypes(exclude=\"object\").drop(columns=[\"quality\"]).columns)\n",
    "categorical_features: list[str] = list(df.select_dtypes(include=\"object\").columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "## Distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16), tight_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i == 11: break\n",
    "    sns.kdeplot(df[numeric_features[i]], fill=True, ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These histograms tell me that the distribution of the data for all of the skewed to the left. This means that I will need to do some data transformation on the fields I decide to keep, so that the data is more normally distributed.\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(11, 1, figsize=(20, 16.5), tight_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    sns.boxplot(x=df[numeric_features[i]], ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These boxplots tell me that there are some outliers in the data. I will need to decide if I want to keep these outliers or not.\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the fields, I decided to do some trail and error to find out what percentile of the data (top and bottom percentile) I want to replace with the median value of the column, keeping the percentile value change to a minimum so as to not impute too many fields, but also to remove as many outliers as possible. Here are the outcomes of my trail and erroring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_config: dict[str, tuple[int, int]] = {\n",
    "    \"fixed_acidity\": (0.03, 0.92),\n",
    "    \"volatile_acidity\": (0, 0.81),\n",
    "    \"citric_acid\": (0.06, 0.95),\n",
    "    \"residual_sugar\": (0, 0.93),\n",
    "    \"chlorides\": (0, 0.92),\n",
    "    \"free_sulfur_dioxide\": (0, 0.9),\n",
    "    \"total_sulfur_dioxide\": (0, 0.95),\n",
    "    \"density\": (0, 0.99),\n",
    "    \"pH\": (0.01, 0.98),\n",
    "    \"sulphates\": (0, 0.96),\n",
    "    \"alcohol\": (0, 0.99),\n",
    "    \"quality\": (0.01, 0.97)\n",
    "}\n",
    "\n",
    "for feature, iqr_range in trim_config.items():\n",
    "    df[f\"{feature}_trimmed\"] = df[feature].clip(\n",
    "        df[feature].quantile(iqr_range[0]),\n",
    "        df[feature].quantile(iqr_range[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(12, 1, figsize=(20, 24), tight_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i == 11:\n",
    "        feature = \"quality\"\n",
    "    else:\n",
    "        feature = numeric_features[i]\n",
    "\n",
    "    sns.boxplot(\n",
    "        pd.melt(df[[feature, f\"{feature}_trimmed\"]]),\n",
    "        x=\"value\",\n",
    "        y=\"variable\",\n",
    "        ax=ax\n",
    "    ).set(\n",
    "        xlabel=None,\n",
    "        ylabel=None\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting the original columns with the trimmed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in numeric_features + [\"quality\"]:\n",
    "    df[feature] = df[f\"{feature}_trimmed\"]\n",
    "    df: pd.DataFrame = df.drop(columns=[f\"{feature}_trimmed\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    df[numeric_features + [\"quality\"]].corr(),\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correlation heatmap tells me that the features have a moderate correlation with each other. This means that I will need to do some feature selection to reduce the number of features I use in my model.\n",
    "\n",
    "<hr />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of each feature with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16), tight_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i == 11: break\n",
    "    sns.lineplot(df, x=\"quality\", y=numeric_features[i], ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs tell me that some of the features are more likely to affect the quality of the wine than others since the lines are more linear than the others, and can be used to predict the quality of the wine better. \n",
    "\n",
    "<hr />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normally Distributing the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to transform each column individually so that they aren't skewed to either direction. I will be applying these changes to the data frame directly but rather by doing it in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_transformer = PowerTransformer(method=\"box-cox\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am plotting the before and after boxcox transformation for each numeric feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(8, 3, figsize=(20, 24), tight_layout=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i in [20, 23]: continue\n",
    "\n",
    "    # some magic to get the right feature name\n",
    "    feature = numeric_features[i - ((i % 6 > 2) + i // 6) * 3]\n",
    "    if i % 6 > 2:\n",
    "        data = PowerTransformer(method=\"box-cox\").fit_transform(df[[feature]])\n",
    "        data.shape = (data.shape[0],)\n",
    "        sns.kdeplot(data, fill=True, color=\"green\", ax=ax)\n",
    "    else:\n",
    "        sns.kdeplot(df[feature], fill=True, ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using a pipeline with a standard scaler to normalize my numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing_transformer = MinMaxScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using a pipeline with a one hot encoder to one hot encode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_transformer = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to split the output into 3 classes, 1 for low quality, 1 for medium quality, and 1 for high quality. This is because my output variable is not exactly continuous (since the value is either 3, 4, 5, 6, 7, 8 or 9). However if I use regression to solve this, I will have to use a continuous output variable, so I decided to use classification instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"quality\"], bins=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above histogram we can roughly split the data into 3 classes, 1 for low quality, 1 for medium quality, and 1 for high quality. I will use this to classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"quality_class\"] = np.where(df[\"quality\"] <= 4, \"low\", np.where(df[\"quality\"] >= 7, \"high\", \"medium\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"quality_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Draft of Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to have at least one draft of the model before I can decide which features to keep, remove and scale for Feature Engineering. Becuase of this, I will run a simple RandomForestClassifier model with BayesSearchCV to find the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_bayes = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters here were found through a previous search, in the cases where I don't want to run bayes again since it can be very time consuming during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_optimal = {\n",
    "    \"max_depth\": 7854,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"n_estimators\": 179\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline([\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"numeric\", Pipeline([\n",
    "            (\"boxcox\", boxcox_transformer),\n",
    "            (\"normalizer\", normalizing_transformer),\n",
    "        ]), df[numeric_features].columns),\n",
    "        (\"categorical\", Pipeline([\n",
    "            (\"onehot\", onehot_transformer)\n",
    "        ]), df[categorical_features].columns)\n",
    "    ])),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        **({} if running_bayes else bayes_optimal),\n",
    "        random_state=hash(\"2100326D\") % 2 ** 32,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"quality_class\"])\n",
    "y = df[\"quality_class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=hash(\"2100326D\") % 2 ** 32)\n",
    "X_train: pd.DataFrame\n",
    "X_test: pd.DataFrame\n",
    "y_train: pd.Series\n",
    "y_test: pd.Series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now depending on whether I've run BayesSearchCV, I will either load the best parameters found or calculate them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_bayes:\n",
    "    # Fix a bug in scikit-optimize\n",
    "    np.int = int\n",
    "\n",
    "    bs = BayesSearchCV(\n",
    "        rfc_pipeline,\n",
    "        {\n",
    "            \"classifier__max_depth\": (1, 10000),\n",
    "            \"classifier__min_samples_leaf\": (1, 5),\n",
    "            \"classifier__min_samples_split\": (2, 5),\n",
    "            \"classifier__n_estimators\": (1, 1000)\n",
    "        },\n",
    "        n_iter=100,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    bs.fit(X_train, y_train)\n",
    "    bayes_optimal = {\n",
    "        \"max_depth\": bs.best_params_[\"classifier__max_depth\"],\n",
    "        \"min_samples_leaf\": bs.best_params_[\"classifier__min_samples_leaf\"],\n",
    "        \"min_samples_split\": bs.best_params_[\"classifier__min_samples_split\"],\n",
    "        \"n_estimators\": bs.best_params_[\"classifier__n_estimators\"]\n",
    "    }\n",
    "\n",
    "    print(\"Best params:\", bayes_optimal)\n",
    "    print(\"Accuracy Score: %.4f\" % accuracy_score(y_test, bs.predict(X_test)))\n",
    "else:\n",
    "    rfc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Accuracy Score: %.4f\" % accuracy_score(y_test, rfc_pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "rfc_pipeline: Pipeline = bs.best_estimator_ if running_bayes else rfc_pipeline\n",
    "_classifier: RandomForestClassifier = rfc_pipeline.named_steps.classifier\n",
    "_onehot: OneHotEncoder = rfc_pipeline.named_steps.transformer.named_transformers_.categorical.named_steps.onehot\n",
    "\n",
    "importances = pd.DataFrame(\n",
    "    _classifier.feature_importances_,\n",
    "    index=list(X_train.drop(columns=[\"type\"]).columns) + list(_onehot.get_feature_names_out()),\n",
    "    columns=[\"Importance\"]\n",
    ").sort_values(by=\"Importance\", ascending=True).T\n",
    "\n",
    "sns.barplot(\n",
    "    data=importances.T[::-1],\n",
    "    x=\"Importance\",\n",
    "    y=importances.columns[::-1],\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I do feature selection, here is a reusable function to fit the model and return it's scores. It modifies the pipelines to work when some columns are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with_features(features: list[str]) -> int:\n",
    "    rfc_pipeline = Pipeline([\n",
    "        (\"transformer\", ColumnTransformer([\n",
    "            (\"numeric\", Pipeline([\n",
    "                (\"boxcox\", boxcox_transformer),\n",
    "                (\"normalizer\", normalizing_transformer),\n",
    "            ]), df[[feature for feature in features if feature != \"type\"]].columns),\n",
    "            (\"categorical\", Pipeline([\n",
    "                (\"onehot\", onehot_transformer)\n",
    "            ]), df[df[[\"type\"] if \"type\" in features else []].columns].columns)\n",
    "        ])),\n",
    "        (\"classifier\", RandomForestClassifier(\n",
    "            **bayes_optimal,\n",
    "            random_state=hash(\"2100326D\") % 2 ** 32,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    rfc_pipeline.fit(X_train[features], y_train)\n",
    "\n",
    "    return accuracy_score(y_test, rfc_pipeline.predict(X_test[features]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to run fit the model with all possible combination of the feature list to find which combination gives me the best score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_combinations = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are the optimal values found in the previous run of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_optimal = ['type', 'fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates']\n",
    "score_optimal = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now depending on whether I've run the combinations already, I will either load the previous data or calculate it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_features = numeric_features + categorical_features\n",
    "\n",
    "if running_combinations:\n",
    "    count = 0\n",
    "    total = len([combination for i in range(1, len(mixed_features)) for combination in itertools.combinations(mixed_features, i)])\n",
    "\n",
    "    for i in range(1, len(mixed_features)):\n",
    "        for features in itertools.combinations(mixed_features, i):\n",
    "            features = list(features)\n",
    "\n",
    "            score = fit_with_features(features)\n",
    "            count += 1\n",
    "            print(f\"{count} out of {total}\")\n",
    "            print(\"Accuracy score: %.4f\" % score)\n",
    "\n",
    "            if score > score_optimal:\n",
    "                print(\"Highscore!\")\n",
    "                combinations_optimal = features\n",
    "                score_optimal = score\n",
    "\n",
    "            print()\n",
    "    print()\n",
    "else:\n",
    "    score_optimal = fit_with_features(combinations_optimal)\n",
    "\n",
    "print(f\"With: {combinations_optimal}\")\n",
    "print(f\"Without: {[feature for feature in mixed_features if feature not in combinations_optimal]}\")\n",
    "print(\"Accuracy score: %.4f\" % score_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [feature for feature in numeric_features if feature in combinations_optimal]\n",
    "categorical_features = [feature for feature in categorical_features if feature in combinations_optimal]\n",
    "\n",
    "X_train = X_train[combinations_optimal]\n",
    "X_test = X_test[combinations_optimal]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I am done with Feature Engineering, I can build the final version of the model. I will also run bayes again to find the best parameters for my model since my dataset changed a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_bayes = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters here were found through a previous search, in the cases where I don't want to run bayes again since it can be very time consuming during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_optimal = {\n",
    "    \"max_depth\": 5036,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 3,\n",
    "    \"n_estimators\": 300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pipeline = Pipeline([\n",
    "    (\"transformer\", ColumnTransformer([\n",
    "        (\"numeric\", Pipeline([\n",
    "            (\"boxcox\", boxcox_transformer),\n",
    "            (\"normalizer\", normalizing_transformer),\n",
    "        ]), df[numeric_features].columns),\n",
    "        (\"categorical\", Pipeline([\n",
    "            (\"onehot\", onehot_transformer)\n",
    "        ]), df[categorical_features].columns)\n",
    "    ])),\n",
    "    (\"classifier\", RandomForestClassifier(\n",
    "        **({} if running_bayes else bayes_optimal),\n",
    "        random_state=hash(\"2100326D\") % 2 ** 32,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now depending on whether I've run BayesSearchCV already, I will either load the best parameters found or calculate them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if running_bayes:\n",
    "    # Fix a bug in scikit-optimize\n",
    "    np.int = int\n",
    "\n",
    "    bs = BayesSearchCV(\n",
    "        rfc_pipeline,\n",
    "        {\n",
    "            \"classifier__max_depth\": (1, 10000),\n",
    "            \"classifier__min_samples_leaf\": (1, 5),\n",
    "            \"classifier__min_samples_split\": (2, 5),\n",
    "            \"classifier__n_estimators\": (1, 1000)\n",
    "        },\n",
    "        n_iter=100,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    bs.fit(X_train, y_train)\n",
    "    bayes_optimal = {\n",
    "        \"max_depth\": bs.best_params_[\"classifier__max_depth\"],\n",
    "        \"min_samples_leaf\": bs.best_params_[\"classifier__min_samples_leaf\"],\n",
    "        \"min_samples_split\": bs.best_params_[\"classifier__min_samples_split\"],\n",
    "        \"n_estimators\": bs.best_params_[\"classifier__n_estimators\"]\n",
    "    }\n",
    "\n",
    "    print(\"Best params:\", bayes_optimal)\n",
    "    print(\"Accuracy Score: %.4f\" % accuracy_score(y_test, bs.predict(X_test)))\n",
    "else:\n",
    "    rfc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Accuracy Score: %.4f\" % accuracy_score(y_test, rfc_pipeline.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the Random Forest Classifier Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rfc_pipeline, \"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
